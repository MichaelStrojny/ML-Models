import torch
import torch.nn as nn
import torch.utils.data as data
import math
import matplotlib.pyplot as plt
import tqdm
import torch.nn.functional as func

# model adds noise to an image (ammount of noise added is based on the value in a list of time steps)
# resblocks extract abstract / high level features from this noisy image. Then, they take a tensor with these feature and construct a tensor of the noise added at every pixel by upscaling)
# by being able to predict what noise was added to the image, model is able to start with a image of pure noise, and remove noise iterativley until it can generate an image

class PosEmbeddings(nn.Module):
    def __init__(self, time_steps, channel_dims):
        super().__init__()
        position = torch.arange(time_steps).unsqueeze(1).float()
        div = torch.exp(torch.arange(0, embed_dim, 2).float() * -(math.log(10000.0) / embed_dim))
        embeddings = torch.zeros(time_steps, embed_dim, requires_grad=False)
        embeddings[:, 0::2] = torch.sin(position * div)
        embeddings[:, 1::2] = torch.cos(position * div)  # added to every odd channel
        self.embeddings = embeddings

    def forward(self, x, t):
        embeds = self.embeddings[t].to(x.device)
        return embeds[:, :, None, None]
        # 1st 2 dims are time_steps and channels
        # embedding added to channel dimension. Last 2 singleton dimensions broadcast across channel dimension
        # so each positional embedding component for each channel is added to all  the spatial locations (h x w) of the corresponding channel

class ResBlock(nn.Module):
  def __init__(self, dropout_prob, group_size, chan):
    super().__init__()
    self.dropout_prob = dropout_prob
    self.group_size = group_size
    self.Conv1 = nn.conv2D(chan, chan*3, kernel_size=3, padding = 1)
    self.Conv2 = nn.conv2D(chan * 3, chan, kernel_size=3, padding = 1)
    self.relu = nn.reLU(inplace=True)
    self.gnorm1 = nn.GroupNorm(group_size, chan)
    self.gnorm2 = nn.GroupNorm(group_size, chan * 3)
    self.dropout = nn.Dropout(p=dropout_prob, inplace=True)

  def forward(self, x, embeddings, embed = True, VAE=False):
    x += embeddings[:, :x.shape[1], :, :]    #slicing ensures embeddings match num of channels in x. since num channels change)
    r = self.conv1(self.relu(self.gnorm1(x)))
    r = self.dropout(r)
    r = self.conv2(self.relu(self.gnorm2(r)))
    return r + x

    # norm data, apply relu for non lonearity (norm prevents relu from causing vanishing gradients)
    # more channels created by conv1. capture more complex features. then condensed to focus on most relavebt features (learns to select most relavent features)
    # Each output channel typically corresponds to a different filter that learns to recognize specific patterns.

class Attention(nn.Module):
    def __init__(self, chan, num_heads, dropout_prob):
        super().__init__()
        self.KQVmatrix = nn.Linear(chan, chan*3)
        self.NeuralNet = nn.Linear(chan, chan)
        self.H = num_heads
        self.dropout_prob = dropout_prob

    def forward(self, x):
        b, c, h, w = x.shape[]
        x = torch.reshape(torch.transpose(x, 1, 3), (b, h*w, c))
          #(batch_size, channels, height, width) to (batch_size, height * width, channels)
          # done because attention mechanism requires a SEQUENCE of features
          # this new shape litteraly has batch size times h*w rows (each is a pixel) each which has a colum with that pixel's value for every channel
        x = self.KQVmatrix(x)
          # channel features triple to make key , query and value
        x = torch.reshape(x, (b, h*w, 3, self.H, c//(3*self.H)))
        x = torch.transpose(torch.transpose(torch.transpose(x, 1, 2), 0, 1), 3, 4)
        q,k,v = x[0], x[1], x[2]
        #each has dims (b, self.H, h*w, c//(3*self.H))
        x = (torch.matmul(q, k.T))//(x.size(dim=-1)**0.5)
        x = nn.Softmax(x, dim=-1)*v
        # return (b, self.H, h*w, c//(3*self.H))
        x = torch.reshape(torch.transpose(x, 2,3), (b, h, w, c*3*self.H))
        # return (b, h, w, c)
        x = self.NeuralNet(x)
        return torch.transpose(torch.transpose(x, 1, 3), 2, 3)
        # ( b C h w )

class UNETblock(nn.Module):
  def __init__(self, upscale, attention, num_groups, dropout_prob, num_heads, chan):
    super().__init__()
     self.ResBlock1 = ResBlock(C=chan, num_groups=num_groups, dropout_prob=dropout_prob)
     self.ResBlock2 = ResBlock(C=chan, num_groups=num_groups, dropout_prob=dropout_prob)
     if upscale:
        self.conv = nn.ConvTranspose2d(chan, chan//2, kernel_size = 3, stride = 2, padding = 1)
        # large kernel allows transposed conv to create smoother transition and capture more spatial context
        # kernel of size 3 with stride 2 doubles the spatial dimensions of the input
        # transpose conv = reverse of conv
     else:
        self.conv = nn.Conv2D(chan, chan*2, kernel_size = 3, stride = 2, padding = 1)
     if attention:
        self.attention_layer = Attention(C, num_heads=num_heads, dropout_prob=dropout_prob)

  def forward(self, x embeddings):
    x = self.ResBlock1(x, embeddings)
    if hasattr(self, 'attention_layer'):
        x = self.attention_layer(x)
    x = self.ResBlock2(x, embeddings)
    return self.conv(x), x

class DiffusionModel()
  #channels list = input channels
  def __init__(self, channels: list, attentions: list, upscales: list, num_groups, dropout_prob, num_heads, input_channels, output_channels, time_steps):
    super().__init__()
    self.num_layers = len(channels)
    final_channels = (channels[-1]//2)+channels[0]     #upscale halves channels and we concatenate 1st encoder residual
    #effectively into the decoder's output. dividing by two ensures that deep features dont overwhelm shallow features
    self.input_conv = nn.Conv2d(input_channels, channels[0], kernel_size=3, padding=1)
    self.output_conv1 = nn.Conv2d(final_channels, final_channels//2, kernel_size=3, padding=1)
    self.output_conv2 = nn.Conv2d(final_channels//2, final_channels, kernel_size=1)
    self.relu = nn.ReLU(inplace=True)
    self.embeddings = PosEmbeddings(time_steps=time_steps, embed_dim=max(channels))
    for i in range(self.num_layers):
            layer = UnetLayer(
                upscale=upscales[i],
                attention=attentions[i],
                num_groups=num_groups,
                dropout_prob=dropout_prob,
                chan=channels[i],
                num_heads=num_heads
            )
            setattr(self, f'Layer{i+1}', layer)

 def forward(self, x, t):
        x = self.input_conv(x)
        residuals = []   #store outputs from each encoder layer
        #iterate over first half of layers in UNET
        for i in range(self.num_layers//2):
            layer = getattr(self, f'Layer{i+1}')
            embeddings = self.embeddings(x, t)
            x, r = layer(x, embeddings)
            residuals.append(r)
        #decoder
        for i in range(self.num_layers//2, self.num_layers):
            layer = getattr(self, f'Layer{i+1}')
            x = torch.cat((layer(x, embeddings)[0], residuals[self.num_layers-i-1]), dim=1)
            #concat across channels. so we are adding more channels
        return self.output_conv2(self.relu(self.output_conv1(x)))
        #output dims match original input

# adding time embeddings in every layer allows the model to maintain a strong connection to the temporal aspect of the data 
      
#################
#################

# Training

torch.manual_seed(9)

model = DiffusionModel(channels, attentions, upscales, num_groups, dropout_prob, num_heads, input_channels, output_channels, time_steps).cuda()

optimizer = optim.Adam(model.parameters(), lr=lr)
loss_fn = torch.nn.MSELoss()

train_data = datasets.MNIST(root='./data', train=True,transform=transforms.ToTensor())
train_data = data.DataLoader(data, batch_size=32, shuffle=True, drop_last=True)

def Noise_Scheduler(time_steps):
    beta = torch.linspace(1e-4, 0.2, time_steps).requires_grad_(False)        
    alpha = torch.cumprod(1-beta, dim=0).requires_grad_(False)
    return alpha

def Train(num_time_steps, visualize=True):
  model.train()
  alpha = Noise_Scheduler(num_time_steps)
  epoch_losses = []
  for i in tqdm(range(epochs)):
      total_loss = 0
      for (x, y) in train_data:
          x = x.cuda()
          x = func.pad(x, (1,1,1,1))     # padding last 2 dimensions = 4 padding vars required (1,1,1,1)
          t = torch.randint(0,num_time_steps,(batch_size,))      #random time steps
          noise = torch.randn_like(x, requires_grad=False)      #random noise
          a = alpha[t].cuda()
          x = ((a**0.5)*x) + (((1-a)**0.5)*noise)
          output = model(x, t)
          optimizer.zero_grad()
          loss = loss_fn(output, noise)
          total_loss += loss.item()
          loss.backward()
          optimizer.step()
      epoch_losses.append(total_loss // len(train_data))

  if visualize:
    plt.figure()
    plt.title("Average Training Loss per Epoch")
    plt.plot(epoch_losses, color='blue')
    plt.xlabel('Epochs')
    plt.ylabel('Average Loss (Per Batch)')
    plt.show()

  return model.state_dict(), epoch_losses
