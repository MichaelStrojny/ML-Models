import numpy as np
import matplotlib.pyplot as plt
import math as m

def init_params(layer_dims):    #list of # of dimensions in each layer
    np.random.seed(3)
    params = {}
    for l in range(1, layer_dims):    #0 = input layer
        params["W"+str(l)] = numpy.random.random((layer_dims[l], layer_dims[l-1]))
        params["B"+str(l)] = numpy.random.random((layer_dims[l], 1))
    return params

def sigmoid(Z):
    return 1 / (1 + math.exp(-Z))

def forward_prop(prev_layer, params):
    storage = []
    for n in range(len(params) // 2):
        Z = params["W"+str(n)].dot(inputlayer) + params["B"+str(n)]   # Z = Av + b
        A = sigmoid(Z)
        storage.append((prev_layer, params['W'+str(l)], params['b'+str(l)]),Z)
    return A, storage

def cost_function(output, true_labels):
    m = true_labels.shape[1]        #number of columns in true_labels (number of examples)
    cost = (-1/m)*(np.dot(np.log(output), Y.T) + np.dot(log(1-output), 1-Y.T))
    return cost

def one_layer_backward(dA_prev, storage):

    weights_biases_and_prev_activations, current_activations = storage
    
    Z =  weights_biases_and_prev_activations
    dZ = dA*sigmoid(Z)*(1-sigmoid(Z))    # Z = Wv + b   dC / dA * dA / dZ   dA / dZ = d(Sigmoid(Z))
    
    A_prev, W, b = weights_biases_and_prev_activations
    m = A_prev.shape[1]     # number of examples
    dW = (1/m)*np.dot(dZ, A_prev.T)      #avg dW...      dC / dZ * dZ / dW = dZ * A_prev.T
    db = (1/m)*np.sum(dZ, axis=1, keepdims=True)   # dC / db = dC / dZ * dZ / db = dZ
    dA_prev = np.dot(W.T, dZ)     # dC / dA_prev = dC / dZ * dZ / dA_prev
    
    # Since we are multiplying Z by W, we transpose W. W is meant to be multiplied by the dimensions of A_prev and output of dimensions of Z. We flip that so it multiplies Z.

    return dA_prev, dW, db

def backprop(output, true_labels, storage):
    
    m = true_labels.shape[1
    dA = - (1 / m) * (np.divide(true_labels, A) - np.divide(1 - true_labels, 1 - A)) 
    # avg dA value for last layer
    
    grads = {}   # gradient for each layer
    L = len(storage)  # of layers
    m = output.shape[1]    # of training examples
    true_labels = true_labels.reshape(output.shape)  
    
    grads['dA'+str(L-1)], grads['dW'+str(L-1)], grads['db'+str(L-1)] = one_layer_backward(storage[L-1])   
    
    #storage[Length_Storage-1]  = last element since storage begins at storage[0]
                          
    for l in reversed(range(L)):    #  0 -> L - 1
        
        dA_prev, dW, db = one_layer_backward(grads["dA" + str(l+1)], storage[l-1])   #2nd last layer
        grads["dA" + str(l-1)] = dA_prev    # dA value for 3nd last layer
        grads["dW" + str(l)] = dW      # dC wr to each weight (matrix) for 2nd last layer
        grads["db" + str(l)] = db
    
    return grads

def Gradient_Descent(LR, params, grads):
    for l in range((len(params) // 2)+1):
        params["W"+str(l)] = params["W"+str(l)] - LR*grads["dW"+str(l)]
        params["b"+str(l)] = params["b"+str(l)] - LR*grads["db"+str(l)]
    return parameters

import numpy as np
import struct

def MNIST_data_processing():
    
    def read_idx(filename):
        with open(filename, 'rb') as f:
            zero, data_type, dims = struct.unpack('>HBB', f.read(4))
            shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))
            return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)

    train_images = read_idx('train-images.idx3-ubyte')
    train_labels = read_idx('train-labels.idx1-ubyte')
    test_images = read_idx('t10k-images.idx3-ubyte')
    test_labels = read_idx('t10k-labels.idx1-ubyte')

    train_images = train_images.astype(np.float32) / 255.0
    test_images = test_images.astype(np.float32) / 255.0

    train = train_images.reshape(train_images.shape[0], -1)
    test = test_images.reshape(test_images.shape[0], -1)

    #stoichastic gradient descent
    split_fraction = 0.2
    num_samples = train_images.shape[0]
    indices = np.arange(num_samples)
    np.random.shuffle(indices)
    
    training_sets = {}
    for n in range(1 // split_fraction):
        training_sets["T"+str(n)] = train_images[indices[n*split_fraction*len(indices):]]
        training_labels["L"+str(n)] = train_labels[indices[n*split_fraction*len(indices):]]
    
def train(params, epochs, LR, layer_dims, training_sets, true_labels):
    
    params = init_params(layer_dims)
    cost_history = []
        
    for l in range(len(training_sets)):
        
        training_sets[l] = prev_layer

        for i in range(epochs):
            A, storage = forward_prop(prev_layer, params)
            cost = cost_function(A, true_labels)
            cost_history.append(np.sum(cost) // m)
            grads = backprop(A, true_labels, storage)
            params = Gradient_Descent(LR, params, grads)
            print(f"Test {i} done")
            
    print(plt.plot(np.array(cost_history), range(cost_history)))
    print(cost_history[-1])

    return params, cost_history
